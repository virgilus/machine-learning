{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fbc96f6-0abb-437a-918e-e6f92482b49c",
   "metadata": {
    "tags": [
     "fr"
    ]
   },
   "source": [
    "# Introduction\n",
    "\n",
    "L'apprentissage automatique (*machine learning*) peut sembler intimidant avec son jargon issu du monde de l'informatique et des statistiques. Pourtant si l'on commence par les bases et que l'on augmente la difficulté progressivement, il est tout à fait possible d'arriver à assimiler les concepts fondamentaux de ce domaine.\n",
    "\n",
    "Ce cours vous donnera un aperçu de la manière dont les *data scientists* élaborent, conçoivent et mettent en application leurs modèles de ML. Vous pourrez alors vous servir de cette base pour continuer à vous perfectionner tout seul, ou bien vous arrêter là après avoir acquis les connaissances nécessaires pour comprendre et dialoguer avec les experts du monde de la data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36319c8-9037-4f4e-82f5-1c31474dd6ea",
   "metadata": {},
   "source": [
    "# Cas-pratique : l'immobilier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d655fb8-04d3-4e7e-9b1a-8b4fa4e98b8c",
   "metadata": {
    "tags": [
     "fr"
    ]
   },
   "source": [
    "Le premier jeu de données que nous allons utiliser concerne l'immobilier. Dans la vie réelle les agents immobiliers savent estimer la valeur d'un bien car ils associent aux différentes caractéristiques d'un bien (nombre de pièces, surface, emplacement etc.) un prix grâce à leur expérience.\n",
    "\n",
    "Le programme que nous allons réaliser va nous permettre de réaliser nous aussi des estimations, c'est-à-dire de de prédire une valeur donnée, mais c'est cette fois c'est l'ordinateur qui va \"apprendre\" de lui-même à grâce aux données que nous allons lui fournir.\n",
    "\n",
    "## Arbre de décision\n",
    "\n",
    "Nous utiliserons pour l'instant un modèle appelé \"arbre de décision\". Ce sont des modèles très instinctifs, faciles à comprendre et à analyser qui pourront rendre service dans bien des cas.\n",
    "\n",
    "Commençons par un exemple très simple :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235ae6d-e4f9-472e-a565-d2546258e25b",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"files/decision_tree_1.png\" alt=\"CPU\" width=\"50%\" align='center'/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c3b219-1f5e-41fb-b2d3-fd14437ad18d",
   "metadata": {
    "tags": [
     "fr"
    ]
   },
   "source": [
    "Ce modèle divise les maisons en deux catégories : celle ayant 2 chambres ou moins et celle ayant plus de 2 chambres, puis il affiche le prix moyen de chaque groupe.\n",
    "\n",
    "Le modèle utilise le jeu de données pour décider comment répartir les maisons dans ces deux groupes, puis à nouveau pour prédire le prix dans chaque groupe. L'étape qui consiste à définir les paramètres d'un modèle à partir de données est appelée entraînement, *fitting* ou **training**. Les données utilisées pour paramétrer ce modèle sont appelées données d'entraînement (*training data*).\n",
    "\n",
    "Les détails de la manière dont le modèle est entraîné (par exemple, la manière de diviser les données) sont assez complexes et nous ne les étudierons que plus tard. Une fois le modèle ajusté, nous pourrons l'appliquer à de nouvelles données afin de prédire le prix d'un logement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e0641-3606-4922-828b-6a9f3cd2eb4c",
   "metadata": {},
   "source": [
    "Nous pouvons prendre en compte davantage de facteurs en utilisant un arbre qui a plus de \"divisions\" (*splits*), c'est-à-dire qui est \"plus profond\". Un arbre de décision qui prend également en compte la taille du terrain de chaque maison pourrait ressembler à ceci."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c028f-67d7-4e09-a1a4-c2b3ea3a1d9c",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"files/decision_tree_2.png\" alt=\"CPU\" width=\"60%\" align='center'/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5955307a-86c0-400e-ab90-2fc7502c9c0a",
   "metadata": {
    "tags": [
     "fr"
    ]
   },
   "source": [
    "Pour prédire le prix d'une maison, on parcourt l'arbre de décision, en choisissant toujours le chemin correspondant aux caractéristiques de cette maison. Le prix prédit pour la maison se trouve en bas de l'arbre et le point en bas de l'arbre où nous faisons une prédiction s'appelle une feuille (*leaf*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595bebb-c8d6-4413-bfa6-1239670f8358",
   "metadata": {},
   "source": [
    "# Exploration avec Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b382c-66bb-4912-b441-2e80516b6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/iowa_housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428a86a-cea4-4262-a22b-649db5ca18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fd721-593a-4432-a360-d90ef5f07de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e09ab6-7fe4-4b0f-a17f-7eddd259d0c0",
   "metadata": {},
   "source": [
    "# Valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ddd0f-a4b7-489d-bdd4-f86a00da3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d75276-8e67-42f0-b170-f4e13f0a11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d40140-002d-42e0-9392-7a66011bf94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().loc[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550dbca-a62b-43d5-898f-8e5cd6efec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_col_len = len(max(df.columns, key=len))\n",
    "max_val_len = len(str(max(df.isna().sum(), key=lambda x : len(str(x)))))\n",
    "\n",
    "for i, num in zip(df.isna().sum().index, df.isna().sum()):\n",
    "    print(f'{i}{(max_col_len - len(i)) * \" \"} | Missing values : {num}{(max_val_len - len(str(num))) * \" \"} | Completion : {round(100 - (num / df.shape[0] * 100))}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c678370-1a5c-41c5-809c-4e66ba381229",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bafbabd-28c8-406a-be5d-7db8a176e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lotarea'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a596594-747f-4f76-b1f5-058eb8d65f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lotarea'].mean().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa21f55-4b50-4eca-a233-18fa857a93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['saleprice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d62b92-a9a7-487e-aff8-d44dca528b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['saleprice'].mean().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1e0c76-5716-461b-93f7-4a8cdba0683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80f30e-0475-4911-af94-c420ead0755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yearbuilt'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0e1af-1ade-4b26-8a35-d8e19ea5bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yearbuilt'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495056aa-52a1-42a9-bb52-3f9b1008ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yearbuilt'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93c336-1cf7-4ba9-bd01-45288d2b009a",
   "metadata": {},
   "source": [
    "# Variable cible\n",
    "\n",
    "La variable cible aussi appelée variable à expliquer, variable dépendante, variable à prédire, ou encore *target* est la variable que nous voulons prédire. Elle est symbolisée par un \"y\".\n",
    "\n",
    "Ici il s'agit de la dernière colonne de notre dataframe qui contient le prix de vente du bien immobilier : ``'saleprice'``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d76d91-0700-4f4e-b92c-4bcdabfda5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['saleprice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d6b31f-df31-49bf-9f86-e23b5fd65181",
   "metadata": {},
   "source": [
    "# Variables explicatives\n",
    "\n",
    "Les variables explicatives, aussi appellées variables à expliquer, variables prédictives ou encore `'features'` sont les variables d'entrées (*input*) de notre modèle. Ce sont grâce à elles que le modèle va pouvoir déterminer la valeur de notre variable de sortie (*output*). Elles sont symbolisées par un \"X\".\n",
    "\n",
    "Le choix de ces variables a une grande incidence sur les résultats. Parfois nous utiliserons toutes les variables que nous avons à disposition, parfois nous n'utiliserons qu'une partie d'entre elles. Il existe un grand nombre de différentes méthodes (logiques, scientifiques, statistiques, informatiques etc.) pour nous aider à faire ce choix.\n",
    "\n",
    "Ici nous utiliserons les variables suivantes comme *features* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a8aa4-5b14-4025-b342-e6c348b448e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "'lotarea',\n",
    "'yearbuilt',\n",
    "'1stflrsf',\n",
    "'2ndflrsf',\n",
    "'fullbath',\n",
    "'bedroomabvgr',\n",
    "'totrmsabvgrd',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3142c48f-1303-4fb6-881b-b175e4ece843",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7186128-aed9-4584-ba9b-667daec62a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43744d58-5880-4058-bbae-407d8765cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb222e9-6224-463a-969d-9d47bfbc1016",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792a9356-6b37-4a30-b5f1-3d898376fbac",
   "metadata": {},
   "source": [
    "### Choix du modèle\n",
    "\n",
    "Nous allons choisir un \"arbre de décision\" aussi appelé *DecisionTreeRegressor* que nous appellerons iowa_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39125ad6-73f9-46e8-858a-329d7e50393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# random_state will allow model reproducibility\n",
    "iowa_model = DecisionTreeRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e9bcb6-30ef-4fd7-8f26-83b299660324",
   "metadata": {},
   "source": [
    "### Ajustement du modèle *fit*\n",
    "\n",
    "L'entraînement du modèle est très simple : une seule ligne de code suffit ! Par convention, on donne d'abord les *features* puis la *target*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed91b5-3bef-4c84-80d6-82e1dba76c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "iowa_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c5f735-8f62-483b-8922-ae86ba97ed2e",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "Une fois notre modèle crée, on peut le visualiser à l'aide de différentes manières."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0bcbe-cb76-4e37-83b4-e7835d7da320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "# print(tree.export_text(iowa_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbdc5b-4b71-4df0-a6e5-6c4bb3f3b58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(iowa_model,\n",
    "               feature_names=X.columns,\n",
    "               max_depth=2,\n",
    "               filled=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da4bd8-6893-487b-bf84-c169fc046637",
   "metadata": {},
   "source": [
    "### Prédictions\n",
    "\n",
    "Notre modèle peut désormais prédire des valeurs à partir d'un ensemble de variables. Essayons de lui faire prédire les résultats à partir des *features* (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7881002-d333-4700-9807-588c1ea9a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = iowa_model.predict(X)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea97cbe-9285-4db6-b074-9a4b0469ebfb",
   "metadata": {},
   "source": [
    "Comparons les 5 premières prédictions avec les 5 premières valeurs de y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7636eb-8482-4b24-b06e-bd8f35b2abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fc7247-200d-4301-98f3-330e0ddd8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c646b-4e2d-4fda-8e3f-3e3cd54f9ec3",
   "metadata": {},
   "source": [
    "C'est étrange on s'attendrait à ce que notre modèle soit un peux faux, mais celui-ci arrive à prédire au dollar près notre variable y !\n",
    "Vérifions cela avec un peu de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15bfec-371f-4007-bbb7-9ee2ad978b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'y':y,'y_pred':y_pred})\n",
    "res['y_pred'] = res['y_pred'].astype(int)\n",
    "res['diff'] = res['y'] - res['y_pred'].round()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2fb8e-3717-454e-90e2-9384f57b13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[res['diff'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244fe13-1cd4-4e40-97d8-cac197d72a31",
   "metadata": {},
   "source": [
    "Sur les 2930 prédictions effectuées, seules 71 ne sont pas correctes. Et pourtant même celles-ci ne sont pas très éloignées du résultat attendus. Avons-nous créé le meilleur modèle possible ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84869bd6-5c22-4314-a3db-afe8b3b47ccd",
   "metadata": {},
   "source": [
    "# Validation d'un modèle\n",
    "\n",
    "Chaque modèle, une fois ajusté, doit être évalué à l'aide de différentes métriques. Une bonne métrique pour évaluer une valeur continue, comme c'est le cas ici, est d'examiner la précision de la prédiction. Pour chaque bien immobilier on va donc calculer la valeur absolue de la différence entre la vraie valeur et la valeur prédite par le modèle :\n",
    "\n",
    "erreur = |vraie valeur - valeur prédite|\n",
    "\n",
    "Si l'on fait ensuite la moyenne de ces valeurs, cela nous donne la MAE (*Mean Absolute Error*). La MAE nous indique quel est l'écart moyen d'une prédiction avec la valeur réelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8eb50d-a930-4449-b8f8-ddf499b7fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f1185-c4be-43a1-83cd-dd597f794301",
   "metadata": {},
   "source": [
    "La précision est donc excellente, mais c'est parce que la manière dont nous avons ajusté notre modèle n'est pas la bonne. Comme les données avec lesquelles nous avons entraîné puis testé le modèle sont les mêmes, il est normal que nous n'obtenons quasiment que des bonnes réponses. Nous avons ici affaire à un cas classique *d'overfitting*.\n",
    "\n",
    "Pour évaluer la robustesse d'un modèle nous allons le tester sur des données que le modèle n'a encore jamais vues. Pour cela nous allons diviser nos données en deux groupes : l'une d'elle va servir à l'apprentissage (*train*), et l'autre à tester le modèle (*test*).\n",
    "\n",
    "Le paramètre \"train_size\" va déterminer la proportion de nos données qui va être utilisée pour l'entraînement. Une valeur de 0.8 signifie que l'on réserve 80% de nos données pour l'apprentissage et 20% pour le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddfd64d-0ab7-487d-97cb-de343dbbd2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Now our data are split in 4 different parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.8)\n",
    "\n",
    "iowa_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = iowa_model.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ce42f-e56f-4120-8ff9-314aa4356669",
   "metadata": {},
   "source": [
    "La MAE est considérablement plus élevée, environ 200 fois ! Comme le prix moyen d'une maison était de l'ordre de $180 000, cela veut dire que notre modèle se trompe d'environ 1/6 du prix. Il y a, bien évidemment, de nombreux moyens d'obtenir un score plus élevé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b8875-2d0b-43e3-9a57-f9856ee19b94",
   "metadata": {},
   "source": [
    "# Les paramètres du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980af4a3-f635-4553-8679-f75f44b8eba0",
   "metadata": {},
   "source": [
    "Un arbre de décision peut être paramétré de nombreuses manières différentes, comme vous pouvez le constater en examinant la [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) relative à notre type de modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61aff3-6d66-490f-bdfb-02e7c7c5eb94",
   "metadata": {},
   "source": [
    "### Différence entre paramètres et hyperparamètres\n",
    "\n",
    "En ML, les hyperparamètres sont les paramètres qui vont encadrer le processus de génération des paramètres internes au modèle.\n",
    "\n",
    "Par exemple dans notre modèle ses paramètres consistent, notamment, en toutes les ramifications qui aboutissent aux feuilles de notre arbre. Ces paramètres ont été déterminés par le modèle au cours de son apprentissage et ont beaucoup varié entre le moment où l'on a lancé l'ajustement et le moment où celui-ci s'est terminé.\n",
    "\n",
    "Les hyperparamètres sont les paramètres qui sont le plus souvent donné par un être humain et qui ne seront pas modifiés au cours de l'apprentissage. Il s'agit de directions générales, de paramètres de plus haut niveau.\n",
    "\n",
    "L'un des hyperparamètre les plus importants de ce modèle est la profondeur de l'arbre. Pour l'instant nous ne lui avions donné aucune directive, donc cet hyperparamètre a été généré par le programme. Examinons-le :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92188eb2-32ab-4d35-b589-30f06ed07551",
   "metadata": {},
   "outputs": [],
   "source": [
    "iowa_model.tree_.max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb497c7-001d-4d19-868f-e4c57fb0cf0d",
   "metadata": {},
   "source": [
    "Il y a au maximum 26 niveau de profondeurs dans notre arbre. A chaque fois que nous ajoutons un niveau de profondeur à notre arbre nous augmentons son nombre maximal de feuilles et donc sa précision. Mais, en contrepartie, le nombre de maisons dans chaque feuille sera de plus en plus réduit ce qui veut dire que les prédictions seront de moins en moins fiables. Il va donc falloir trouver un compromis entre précision et fiabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ace10d-8f91-4586-bafe-2e554a9d4f73",
   "metadata": {},
   "source": [
    "### *Overfitting* et *underfitting*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9873663-a86a-4647-832a-ec98ee22abe5",
   "metadata": {},
   "source": [
    "Les phénomènes d'*overfitting* et d'*underfitting* sont des concepts centraux du *machine learning*.\n",
    "\n",
    "- On parle d'*overfitting* lorsque les résultats de notre modèle collent de très près aux données avec lesquelles il a été entraîné mais se trompe beaucoup lorsqu'on l'applique sur des données inconnues. C'est ce qui arrivera si notre arbre de décision est trop profond.\n",
    "\n",
    "- On parle d'*underfitting* lorsque le modèle n'arrive pas à faire la distinction entre des caractéristiques essentielles de nos données. Celui-ci aura un mauvais score sur les données d'entraînement, mais aussi sur les données réservées pour le test. C'est ce qui arrivera si notre modèle n'est pas assez profond."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf55b70-5c2e-4bbe-9f74-e18bd2c6c7d4",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"files/underfitting_and_overfitting.png\" alt=\"CPU\" width=\"75%\" align='center'/> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a7192-2a69-4ae0-a96f-056f601ec066",
   "metadata": {},
   "source": [
    "Le graphique ci-dessus montre la variation de la MAE en fonction de la profondeur d'un arbre de décision. Le terme de \"validation\" désigne ici le jeu de \"test\". Quelques remarques sur le graphique :\n",
    "\n",
    "- Le modèle aura, en moyenne, toujours un meilleur score lorsqu'il prédit des données qui proviennent de son jeu d'entraînement plutôt que des données inconnues provenant du jeu de test.\n",
    "\n",
    "- L'augmentation de la profondeur va permettre dans un premier temps d'améliorer le modèle que ce soit sur le *train* ou le *test*.\n",
    "\n",
    "- Il arrive un moment où l'augmentation de la profondeur apportera un gain de précision sur le *train* mais ou la MAE va elle commencer à augmenter sur le *test*. C'est le phénomène d'overtiffing.\n",
    "\n",
    "Le but des hyperparamètres est donc de trouver ce point d'équilibre qui devrait nous permettre de maximiser les résultats du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55157dc9-6b1c-4a33-8d20-0c64d879fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, X_train, X_test, y_train, y_test):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e6c5c-5c63-4825-8e65-d60051a759e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "get_mae(50, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be26c2-56f8-4bc2-a6b3-3f753fb739b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for max_leaf_nodes in [2, 5, 25, 30, 40, 50, 100, 200]:\n",
    "    mae = get_mae(max_leaf_nodes, X_train, X_test, y_train, y_test)\n",
    "    d[max_leaf_nodes] = mae\n",
    "    print(f\"Max leaf nodes: {max_leaf_nodes} \\t\\t Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876f2ea-11bd-4417-a576-1b4439d3816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame.from_dict(d.items())\n",
    "             .rename(columns={0 : 'max_leaf_nodes', 1 : 'mae'})\n",
    "             .plot(x='max_leaf_nodes', y='mae', color='red'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25211dd-cec4-42b8-90d9-86a6e944ac6d",
   "metadata": {},
   "source": [
    "Graphiquement le meilleur hyperparamètre semble être autour de 40. On pourrait le trouver automatiquement à l'aide de certaines techniques que nous verrons plus tard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e818e4-788c-4cc0-baf1-a1ab50e1920e",
   "metadata": {},
   "source": [
    "# Quel avenir pour notre modèle ?\n",
    "\n",
    "Une fois avoir trouvé les meilleurs hyperparamètres, on peut entraîner à nouveau le modèle mais en utilisant cette fois le jeu de données en entier afin d'améliorer encore un peu la précision. Puis nous pourrions le tester sur des données réelles, provenant d'un jeu de données différents afin de voir comment il se comporte.\n",
    "\n",
    "Une autre possibilité serait d'utiliser un modèle différent et voir si celui-ci se comporte mieux ou moins bien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4dc77-444c-4634-91c9-adccf93799af",
   "metadata": {},
   "source": [
    "# Pour aller plus loin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e7841-915b-4144-a232-3050cf908a25",
   "metadata": {},
   "source": [
    "### Sélection de colonnes sur la base du taux de valeurs manquantes\n",
    "\n",
    "Un ``df.dropna()`` appliqué sur toutes les colonnes nous supprimerait toutes les lignes de notre dataframe. On peut cependant choisir d'éliminer toutes les colonnes qui ont un taux de complétion inférieures à 94% (par exemple), ce qui nous permet de garder au moins 94% de notre jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae71787-0c87-4d73-93b4-2338055cfd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple 1\n",
    "(df['garagetype'].isna().sum() / df.shape[0]) < 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ebcc5-dba5-4f7e-bd2c-38de57235048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple 2\n",
    "(df['miscfeature'].isna().sum() / df.shape[0]) < 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872bcba-110b-4379-8be2-f0a1a2e7f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [col for col in df.columns if (df[col].isna().sum() / df.shape[0]) < 0.06]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf442389-b4be-4185-93e1-ed6ef9c6fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df.dropna().shape, df[good_cols].dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb2159-1904-4017-a7c3-12ff7836dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[cols_to_keep].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e940e0-cc7a-436d-91b2-4541a76e4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "(new_df.isna().sum() > 0).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
