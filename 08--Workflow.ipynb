{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0999ed1c-79a8-45f8-9133-9159004ac020",
   "metadata": {},
   "source": [
    "# Workflow\n",
    "\n",
    "Now we've seen the theory, it's time to see how to use it with Python, and especially how to create a pipeline.\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "### Parametrics models\n",
    "\n",
    "So far we've seen **parametrics models** (logistic, linear regression) where :\n",
    "\n",
    "- $\\hat{y}=f_\\beta(X)$\n",
    "-  Meaning that we have some parameters $\\beta$ to model an arbitrary large $n$ datapoints.\n",
    "\n",
    "Those models are very fast to compute. You can apply on them the stochastic descent gradient.\n",
    "\n",
    "But those models can't find complex patterns unless we create complex features (xÂ²...).\n",
    "\n",
    "Each time we know how many parameters we're trying to optimize, those are parametrics models. (So technically Neural Networks are parametric models.)\n",
    "\n",
    "### Non Parametrics models\n",
    "\n",
    "**KNN**, **SVM** are non-parametrics. We don't know how many parameters we need to optimize.\n",
    "\n",
    "During a ```KNN.fit()```, it doesn't compute trying to minimize a loss function, it's recording the distance between every point.\n",
    "Those models can find complex features but it takes a lot of time to compute on large datasets, and they tend to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551dd69a-a49b-43fc-aa2e-ee193309f79e",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"files/sklearn_cheatsheet.png\" width=\"85%\" source='https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html' align='center'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48f34f4-97a2-4305-ac93-766aa1ec002d",
   "metadata": {},
   "source": [
    "**Regression** : If you have a lot of samples (more than 100K), you can go with a **SGD Regressor** (Stochatisc Gradient Descent). If not, Lasso if you think you have few features of importance, Ridge if you're not sure. If this fails, you can go with a **SVR-rbf** (Support Vector Regression - Radial Basis Function) which is non-parametric.\n",
    "\n",
    "**Classification** (with a labelled dataset) : If you have a lot of data, you can also use a SGD classifier. And if it doesn't work, try with a kernel approximation. Otherwise linear models such as Linear SVC  or Logistic classification. If not, Naive Bayes, KNeighbors classifier, or SVC, ensemble classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a43e176-c4b4-46d6-91fc-829df4546005",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline\n",
    "\n",
    "When trying to create a model, you've got many choices to do :\n",
    "\n",
    "1. **Data preparation**\n",
    "\n",
    "- Cleaning the data.\n",
    "- Create new features.\n",
    "- Scaling the valies.\n",
    "\n",
    "2. **Modelisation**\n",
    "\n",
    "- Choosing the right model.\n",
    "- Choosing the right hyperparameters.\n",
    "\n",
    "3. **Compare results**\n",
    "\n",
    "- Compare results between different models.\n",
    "\n",
    "So what if a pipeline can help us to simplify all these steps?\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"files/pipeline.png\" width=\"55%\" source='from Raschka, Sebastian. Python machine learning. Birmingham, UK: Packt Publishing, 2015.' align='center'/>\n",
    "</div>\n",
    "\n",
    "The train and the test must undergo the same transformations, but must be kept separated at all stages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d9ec3-cf12-415c-9f4f-c5a25490c719",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02313ae-8a49-42b0-82ec-3441e535d200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/insurance_workflow.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd2d0cd-f393-49d1-ab8c-96475c282e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns='charges')\n",
    "y = df['charges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c10f9-eab2-45a5-9214-1f52b8eee8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f0f4d3-045f-434c-81d8-6a4fff0399f4",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "We're going to :\n",
    "\n",
    "- Impute missing values.\n",
    "- Scale numerical features.\n",
    "- Encode categorical features\n",
    "- fine tune model and preprocessing\n",
    "\n",
    "When working on a new project, it's a good habit to start the pipeline right away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fed203-7b3a-498d-9d87-ad01c1fba7a4",
   "metadata": {},
   "source": [
    "## With one numerical Series (age)\n",
    "\n",
    "A Pipeline in sklearn takes as input a list of tasks. In the cell below the first task is an 'imputer', the second a 'standard_scaler'. Let's name them, it's going to be handy later.\n",
    "\n",
    "Then the pipeline fits from first to last. So now it fits the ```SimpleImputer```, than the ```StandardScaler```.\n",
    "We can fit a Series or an entier DataFrame. Let's start simple with only one Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ed919-6f9d-44e3-b8e5-67a71e787b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess \"age\"\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Build the pipeline with the different steps\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")), # replace missing values\n",
    "    ('standard_scaler', StandardScaler())\n",
    "                    ])\n",
    "\n",
    "pipeline.fit(X_train[['age']])\n",
    "pipeline.transform(X_train[['age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba5938a-64ef-4d81-b568-109e59c1e1a2",
   "metadata": {},
   "source": [
    "## Column Transformer\n",
    "\n",
    "But all our features have different characteristics. A numeric feature will not be preprocessed the same as a categorical feature. So we can use the class ```ColumnTransformer``` to do that.\n",
    "\n",
    "<div>\n",
    "<img src=\"files/column_transformer.png\" width=\"55%\" source='https://bait509-ubc.github.io/BAIT509/lectures/lecture5.html' align='center'/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a10464-7f3b-4037-8c1f-412da8e03287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For numeric features\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For categorical features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Impute and then scale numerical values:\n",
    "num_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "    ('standard_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Encode categorical values\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Parallelize \"num_transformer\" and \"cat_transfomer\"\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_transformer', num_transformer, ['age', 'bmi']),\n",
    "    ('cat_transformer', cat_transformer, ['smoker', 'region'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7e91e-5fef-4c27-82be-ada043f93006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizing Pipelines in HTML\n",
    "# If it doesn't display properly try this:\n",
    "# from sklearn import set_config; set_config(display='diagram')\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9efc14-24e3-428f-8a13-8bd2f0f84474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_transformed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3771dee-3875-431c-b5d6-ab84bae2aa8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# original X_train\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc442a5-36b3-444e-9d45-8bc8301afed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessed training set\n",
    "pd.DataFrame(\n",
    "    X_train_transformed,\n",
    "    columns=preprocessor.get_feature_names_out()\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba7d1b2-1098-4ee4-b0d1-0b50debb0770",
   "metadata": {},
   "source": [
    "### Other columns\n",
    "\n",
    "The column 'Children' is not here anymore? We can add a parameter to the ColumnTransformer to keep the features as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc39685-75ff-45bc-b405-9720ef53681e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [('num_transformer', num_transformer, ['age', 'bmi']),\n",
    "    ('cat_transformer', cat_transformer, ['smoker', 'region'])],\n",
    "    remainder='passthrough')\n",
    "\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "pd.DataFrame(\n",
    "    X_train_transformed,\n",
    "    columns=preprocessor.get_feature_names_out()\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e243e3de-5c64-46d5-a06b-83c827cca220",
   "metadata": {},
   "source": [
    "### Custom Functions\n",
    "\n",
    "Sometimes we need to perform operations which don't already exist in sklearn, that's why ```FunctionTransformer``` is here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f53e54a-9d0d-4c83-a9d9-cbebb8a3890c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Create a transformer that compresses data to 2 digits (for instance!)\n",
    "# rounder = FunctionTransformer(np.round)\n",
    "\n",
    "# We can use a lambda function for more customizable functions\n",
    "rounder = FunctionTransformer(lambda x: np.round(x, decimals=2)) # x is an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e3ce6-c0b4-444a-bf0a-9e4d8a1baf48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add it at the end of our numerical transformer\n",
    "num_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rounder', rounder)])\n",
    "\n",
    "# Encode categorical values\n",
    "cat_transformer = OneHotEncoder(drop='if_binary',\n",
    "                                handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_transformer', num_transformer, ['bmi', 'age']),\n",
    "    ('cat_transformer', cat_transformer, ['region', 'smoker'])],\n",
    "    remainder='passthrough')\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a35fcbc-19af-433e-a6e4-7bd2ee7ff217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(preprocessor.fit_transform(X_train)).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8dbe8-2802-49a7-a0d8-0e46941eb53d",
   "metadata": {},
   "source": [
    "### Stateless transformations\n",
    "\n",
    "The ```FunctionTransformer``` class only works with **stateless transformations**.\n",
    "\n",
    "**Stateless transformations** are transformations which don't need to store information during ```.fit(X_train)``` that would be used for the ```.transform(X_test)```.\n",
    "\n",
    "Since a **stateless transformation** doesn't learn anything, fitting is impossible, it does nothing other than transform!\n",
    "Examples of transformations which don't \"learn\" anything:\n",
    "\n",
    "$( X \\rightarrow \\log(X)$\n",
    "\n",
    "$(X_1, X_2) \\rightarrow X_1 + 5X_2$\n",
    "\n",
    "You can apply those functions directly on your X without having to store information. It doesn't \"fit\" anything, it just performs a transformation.\n",
    "\n",
    "### Statefull transformations\n",
    "\n",
    "But if we use a **StandardScaler** or a **MinMaxScaler**, those transformations compute some parameters.\n",
    "\n",
    "- When we use a **MinMaxScaler**, we need to store the ```min()``` and the ```max()``` of the train set.\n",
    "- When we apply a **StandardScaler** we need to store the mean and the standard deviation.\n",
    "\n",
    "And so on...\n",
    "\n",
    "### A Class for a custom function\n",
    "\n",
    "We can create our own class based on the scikitlearn class to resolve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a1758-6424-4d6d-9bb0-5c0dff74784d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An empty transformer\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator # Classes to herit\n",
    "\n",
    "class MyCustomTranformer(TransformerMixin, BaseEstimator):\n",
    "    # BaseEstimator generates the get_params() and set_params() methods that all Pipelines require\n",
    "    # TransformerMixin creates the fit_transform() method from fit() and transform()\n",
    "\n",
    "    def __init__(self): # empty if no hyperparameters\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Here you store what needs to be stored/learned during .fit(X_train) as instance attributes\n",
    "        # Return \"self\" to allow chaining .fit().transform()\n",
    "        pass\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Return the result as a DataFrame for an integration into the ColumnTransformer\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e04c71-4028-4920-914d-7fd3199bff09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_transformer = MyCustomTranformer()\n",
    "my_transformer.fit(X_train)\n",
    "my_transformer.transform(X_train)\n",
    "my_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea3182-e384-4c0e-84a2-c9a7f5c667c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Union\n",
    "\n",
    "FeatureUnion applies a list of transformer objects in parallel to the input data, then concatenates the results.\n",
    "\n",
    "This is useful to combine several feature extraction mechanisms into a single transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0483546-e3ac-4000-baa3-44d41b4c943e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### bmi_age_ratio feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead576fe-3bf0-4018-820f-4d784d70a2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a647c9-73cb-45df-9899-2828330b885e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Create a custom transformer that multiplies/divides two columns\n",
    "# Notice that we are creating this new feature completely randomly just as an example\n",
    "bmi_age_ratio_constructor = FunctionTransformer(lambda df: pd.DataFrame(df[\"bmi\"] / df[\"age\"]))\n",
    "\n",
    "union = FeatureUnion([\n",
    "    ('preprocess', preprocessor), # columns 0-7, it's a ColumnTransformer\n",
    "    ('bmi_age_ratio', bmi_age_ratio_constructor) # new column 8, it's a FunctionTransformer\n",
    "])\n",
    "\n",
    "union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1266a-905a-4acb-afe7-fdc7c2cb488f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(union.fit_transform(X_train)).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68969000-408f-4d4b-b42c-9cef94a29234",
   "metadata": {},
   "source": [
    "### Summary with \"make_\" shortcuts.\n",
    "\n",
    "It's a faster way to build pipeline. That's the same thing but you don't have to name it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42227c1-52fb-41f9-8253-854e41d1c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36aef8a-2803-4c32-b7c0-2135746a4bbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import make_union\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ad45c-87b3-45f1-8010-d3a1814a937f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instead of :\n",
    "\n",
    "Pipeline([\n",
    "    ('my_name_for_the_imputer', SimpleImputer()),\n",
    "    ('my_name_for_the_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941e9db-6252-4e5b-bce8-205fa14f0eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can write :\n",
    "\n",
    "make_pipeline(SimpleImputer(), StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeddc0eb-ed26-4596-ac58-e2435cc9cfb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code is more compact\n",
    "\n",
    "num_transformer = make_pipeline(SimpleImputer(), StandardScaler())\n",
    "cat_transformer = OneHotEncoder()\n",
    "\n",
    "preproc_basic = make_column_transformer(\n",
    "    (num_transformer, ['age', 'bmi']),\n",
    "    (cat_transformer, ['smoker', 'region']),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "preproc_full = make_union(preproc_basic, bmi_age_ratio_constructor)\n",
    "\n",
    "preproc_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0e9ee-91a8-4782-ac79-ab0dcdbd7d58",
   "metadata": {},
   "source": [
    "### Automatic features selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58577397-0a93-4b2b-bd68-731d2000b16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd96174-15ff-49f0-a1d8-9d79c84fd7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "num_col = make_column_selector(dtype_include=['float64'])\n",
    "cat_col = make_column_selector(dtype_include=['object','bool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b713a82-2b58-4ae7-8928-9920d6b7ba74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "# Nothing is \"hard coded\", it could work on a dataset with any column names\n",
    "num_transformer = make_pipeline(SimpleImputer(), StandardScaler())\n",
    "num_col = make_column_selector(dtype_include=['float64'])\n",
    "\n",
    "cat_transformer = OneHotEncoder()\n",
    "cat_col = make_column_selector(dtype_include=['object','bool'])\n",
    "\n",
    "preproc_basic = make_column_transformer(\n",
    "    (num_transformer, num_col),\n",
    "    (cat_transformer, cat_col),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "preproc_full = make_union(preproc_basic, bmi_age_ratio_constructor)\n",
    "\n",
    "preproc_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ff18d-4d0a-4f81-9d64-bbb729e675cd",
   "metadata": {},
   "source": [
    "### What next?\n",
    "\n",
    "You can apply them on you train and test to :\n",
    "    \n",
    "- fit them\n",
    "- transform them\n",
    "- fit transform them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ca835-3d57-45cf-99ed-3efe950da849",
   "metadata": {},
   "source": [
    "## Using pipeline\n",
    "\n",
    "### Adding a model inside a pipeline\n",
    "\n",
    "Model objects can be plugged into Pipelines.\n",
    "Pipelines inherit the methods of the last object in the sequence\n",
    "- Transformers: fit and transform\n",
    "- Models: fit, score, predict, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306178df-f314-4c85-9c3c-71843f6909c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Preprocessor\n",
    "num_transformer = make_pipeline(SimpleImputer(), StandardScaler())\n",
    "cat_transformer = OneHotEncoder()\n",
    "\n",
    "preproc = make_column_transformer(\n",
    "    (num_transformer, make_column_selector(dtype_include=['float64'])),\n",
    "    (cat_transformer, make_column_selector(dtype_include=['object','bool'])),\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Add estimator\n",
    "pipeline = make_pipeline(preproc, Ridge())\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7b36f-6443-4b48-a3ef-854ce0a96824",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a490aa1-ca74-49e3-8539-36ecd1ea0de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "pipeline.predict(X_test.iloc[0:1])\n",
    "\n",
    "# Score model\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7598b912-5025-4532-986b-4064f7c5d9a3",
   "metadata": {},
   "source": [
    "But our score isn't very reliable because it wasn't cross validated, we stayed to the initial split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4160a3-a8de-403e-93c0-a6c3dbf99ba0",
   "metadata": {},
   "source": [
    "### Cross validation of a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead25d3-5893-4627-8ebc-bbecde2e311d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cross-validate Pipeline. Scaling and all the others informations are applied separately on each fold. No data leakage.\n",
    "cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cdecc2-f4b8-4381-bfca-3f012047557d",
   "metadata": {},
   "source": [
    "### Grid Search with a Pipeline\n",
    "\n",
    "Grid Searching allows you to check which combination of preprocessing/modeling hyperparameters works best.\n",
    "It is possible to Grid Search the hyperparameters of any component of the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98e281-a272-44a6-9cb4-da8147707019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304abaca-b78f-4d75-b450-964d553243a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid={\n",
    "        # Access any component of the Pipeline\n",
    "        # and any available hyperparamater you want to optimize\n",
    "        'columntransformer__pipeline__simpleimputer__strategy': ['mean', 'median'],\n",
    "        'ridge__alpha': [0.1, 0.5, 1, 5, 10]\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring=\"r2\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500ec50-2b52-403c-8af2-b02131a09c65",
   "metadata": {},
   "source": [
    "Now that we know that ridge_alpha = 1 is the best, we can try to change our initial list ```[0.1, 0.5, 1, 5, 10]```, and replace with numbers around 1. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ed5c3-fab9-4e2a-ab8e-3f4ac10a3edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde39e71-2c9f-4f91-a6d6-fc6badc64e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_tuned = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a964f-6df6-4679-afee-0e01987d4568",
   "metadata": {},
   "source": [
    "### Debug the pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9897f6dd-8ef4-429a-9fff-a4dee5a25de6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access the components of a Pipeline with `named_steps`\n",
    "pipeline_tuned.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3421f-1c36-46a1-b086-ac93a9ae0991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db85ae1-484a-4de6-8fe6-4761e03a2242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_tuned.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0561d-8472-4e49-9c36-e06be41711bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check intermediate steps\n",
    "print(\"Before preprocessing, X_train.shape = \")\n",
    "print(X_train.shape)\n",
    "print(\"After preprocessing, X_train_preprocessed.shape = \")\n",
    "pipeline_tuned.named_steps[\"columntransformer\"].fit_transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a03c4f-fb6f-47c4-b1d3-9b3103582c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Other example\n",
    "pipeline_tuned.named_steps['columntransformer'].transformers_[2][1].fit_transform(X_train[['age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df2489-3e44-486a-8116-4f193774d5b6",
   "metadata": {},
   "source": [
    "### Export models\n",
    "\n",
    "You can export and load a model. Make sure you're using the same virtual environement!\n",
    "\n",
    "You can now deploy your model on a server and try it on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12252e1f-d0b2-4742-a132-1f04aa63284b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle # binary format to export a python object\n",
    "\n",
    "# Export Pipeline as pickle file\n",
    "with open(\"pipeline.pkl\", \"wb\") as file:\n",
    "    pickle.dump(pipeline_tuned, file)\n",
    "\n",
    "# Load Pipeline from pickle file\n",
    "my_pipeline = pickle.load(open(\"pipeline.pkl\",\"rb\"))\n",
    "\n",
    "my_pipeline.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
