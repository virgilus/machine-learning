{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines and Custom Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/olist.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each observation of the dataset represents an item being delivered from a  `seller_state` to a `customer_state`. \n",
    "- Other columns describe the packaging properties of each item.\n",
    "\n",
    "The target is the number of days between the order and the delivery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check target\n",
    "sns.histplot(df['days_until_delivery']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['days_until_delivery'])\n",
    "y = df['days_until_delivery']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **>>>** Create a scikit-learn pipeline named `pipe` that:\n",
    "\n",
    "- Engineers a `volume` feature from the dimensions features (so you need to multiply `product_length_cm` with `product_height_cm` and `product_width_cm`). To help you the function is already created, it takes a dataframe and outputs a new dataframe.\n",
    "- Preserves the original product dimensions features for training.\n",
    "- Scales all numerical features.\n",
    "- Encodes the categorical features.\n",
    "- Adds a default `Ridge` regression estimator.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "- For this exercice, ignore the holdout method, so no need to use `train_test_split()`!\n",
    "- If you are in the mood, you can try to build your own ```class``` called \"ColumnMultiplier\", but you really don't have to.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "- There are many ways to create your preprocessed matrix (using `ColumnTransformer` and/or `FeatureUnion`). \n",
    "    \n",
    "- If your transformed feature matrix look weird, it may be stored as \"sparse\" by the default behavior of `OneHotEncoder(sparse_output=True)`. Use `.todense()` to turn it back to a dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multiply(df): return pd.DataFrame(df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You probably won't use all of these functions, but just in case, let's import them all!\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "# Code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Using a Class as a ColumnMultiplier (you don't need to do it, but you can see an exemple)\n",
    "\n",
    "# Create a class\n",
    "class ColumnMultiplier(TransformerMixin, BaseEstimator):\n",
    "# TransformerMixin generates a fit_transform method from fit and transform\n",
    "# BaseEstimator generates get_params and set_params methods\n",
    "    \n",
    "    # Create parameters \"column_1\", \"column_2\", \"column_3\" to choose which columns of dataframe to multiply\n",
    "    def __init__(self, column_1, column_2, column_3):\n",
    "        self.column_1 = column_1\n",
    "        self.column_2 = column_2\n",
    "        self.column_3 = column_3\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        # Multiplication\n",
    "        multiplied_features =X[self.column_1]*X[self.column_2]*X[self.column_3]\n",
    "        \n",
    "        # Return result as dataframe (for integration into ColumnTransformer)\n",
    "        return pd.DataFrame(multiplied_features, columns=['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_preprocessor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(final_preprocessor3.fit_transform(X)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_preprocessor3.fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **>>>** Let's imagine `df` is your entire training set. \"Cross_validate\" your pipeline on this dataset (therefore low $r2$ score are expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# Code here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Expected results** : A $r²$ around 0.15824 for cv=10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "❓ **>>>** Now, imagine you just received an new order `new_obs`, predict it's duration of delivery in a variable `prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_obs = {'customer_state': ['RJ'],\n",
    "           'seller_state': ['SP'],\n",
    "           'product_weight_g': [1825],\n",
    "           'product_length_cm': [53],\n",
    "           'product_height_cm': [10],\n",
    "           'product_width_cm': [40]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code here!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ **Expected results** : ```array([20.67221182])```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
